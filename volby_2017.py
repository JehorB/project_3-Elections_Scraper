"""
projekt_3.py: t≈ôet√≠ projekt do Engeto Online Python Akademie
Elections Scraper

author: Yehor Baranov
email: yhr.baranov@post.cz
"""

import csv
import re
import sys
from time import sleep

from bs4 import BeautifulSoup
import requests

# Kontrola vstupu p≈ô√≠kazov√©ho ≈ô√°dku / Checks command line arguments
def validate_cmd():
    if len(sys.argv) != 3:
        print(f"Chyba: Oƒçek√°v√°ny jsou 2 argumenty - n√°zev uzem√≠ a n√°zev souboru s daty.")
        print(f"Pou≈æit√≠: python volby_2017.py <n√°zev_uzem√≠> <vysledky_obec.csv>")
        print(f"Zkuste to znovu")
        sleep(3)
        sys.exit(1)

    cmd_vstup = [arg.strip() for arg in sys.argv[1:]]
    return cmd_vstup

# Kontrola 1.argumentu p≈ô√≠kazov√©ho ≈ô√°dku / Checks arguments command line arguments
def validate_args_okres(uzemi, okres_dict):
    translit_map = str.maketrans("√°ƒçƒè√©ƒõ√≠≈à√≥≈ô≈°≈•√∫≈Ø√Ω≈æ√öƒå≈†≈Ω", "acdeeinorstuuyzUCSZ")
    if uzemi in okres_dict:
        return okres_dict[uzemi]
    uzemi_translit = uzemi.translate(translit_map).lower()
    for key, url in okres_dict.items():
        if key.translate(translit_map).lower() == uzemi_translit:
            return url
    
    # Pr√°ce s chybou
    first_letter = uzemi[0].lower() # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—É—é –±—É–∫–≤—É –≤–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –æ–∫—Ä—É–≥–∞
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –æ–∫—Ä—É–≥–æ–≤
    podobne_okresy = [okres for okres in okres_dict if okres.lower().startswith(first_letter)]
    # –í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫
    if podobne_okresy:
        print("üìå Mo≈æn√° jste mysleli:", ", ".join(podobne_okresy))
    else:
        print("üìå ≈Ω√°dn√© podobn√© okresy nenalezeny.")
    sleep(3)
    sys.exit(1)


# Kontrola 2.argumentu p≈ô√≠kazov√©ho ≈ô√°dku / Checks arguments command line arguments
def validate_args_filename(filename: str) -> str:
    file_name = re.sub(r'[\\/:;"*?<>|]', '_', filename) # Odstranƒõn√≠ neplatn√Ωch znak≈Ø
    if not file_name.endswith(".csv"):
        file_name += ".csv"
    return file_name


# St√°hne HTML str√°nku a vr√°t√≠ jej√≠ obsah jako text / Downloads HTML page
def get_html(url):
    headers = {
        "User-Agent":
        ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/109.0.0.0 Safari/537.36")
    }

    try:
        response = requests.get(url, headers=headers)
        # P≈ôid√°me pauzu mezi po≈æadavky (zabr√°n√≠ blokaci IP)
        sleep(1)
        if response.status_code != 200:
            print(f"Chyba p≈ôi naƒç√≠t√°n√≠ str√°nky ({url}): {response.status_code}")
            sys.exit(1)  # Ukonƒç√≠ program s chybov√Ωm k√≥dem 1
        
        return response.text  # Vrac√≠ HTML obsah str√°nky jako text
    
    except requests.exceptions.RequestException as e:
        print(f"Chyba p≈ôi p≈ôipojen√≠ k URL ({url}): {e}")
        sys.exit(1)  # Ukonƒç√≠ program p≈ôi s√≠≈•ov√© chybƒõ


# Naƒçte hlavn√≠ str√°nku, vytvo≈ô√≠ seznam url adres na str√°nky okresu / Loads the home page
def get_okres_url(html):
    soup = BeautifulSoup(html, "html.parser")
    okres_dict = {}
    # Prefix odkazu
    base_url = "https://www.volby.cz/pls/ps2017nss/"
    # Regul√°rn√≠ vyhled√°vac√≠ v√Ωraz pro <td headers=‚Äût1sa3‚Äú a≈æ po t14sa3">
    rows = soup.find_all("tr")
    td_nazev = [row.find("td", attrs={"headers": re.compile(r"t\d+sa1 t\d+sb2")}) for row in rows]
    td_link = [row.find("td", attrs={"headers": re.compile(r"t\d+sa3")}) for row in rows]

    # Z√≠skat seznamy mƒõst a URL adres
    if any(td_nazev) and any(td_link):
        mesto = [td.get_text(strip=True) for td in td_nazev if td] # N√°zev okresu
        a_tag = [link.find("a", href=True) for link in td_link if link]  # Odkaz na okres

    # Kontrola d√©lek seznam≈Ø
    assert len(mesto) == len(a_tag), "Chyba: seznamy maj√≠ r≈Øznou d√©lku!"

    # Z√°pis v√Ωsledk≈Ø do slovn√≠ku {mƒõsto: url_adresa}
    for name, tag in zip(mesto, a_tag):
        full_url = base_url + tag["href"]  # √öpln√Ω odkaz
        okres_dict[name] = full_url  # P≈ôid√°n√≠ do slovn√≠ku
    
    return okres_dict





if __name__ == "__main__":
    cmd_args = validate_cmd()
    uzemi, filename = cmd_args
    filename = validate_args_filename(filename)
    # Odkaz na v√Ωsledky voleb
    url_volby_2017 = "https://www.volby.cz/pls/ps2017nss/ps3?xjazyk=CZ"
    html_main = get_html(url_volby_2017)
    okres_urls = get_okres_url(html_main)
    url_uzemi = validate_args_okres(uzemi, okres_urls)
    
    # Testy: zakomentuj p≈ôed odevzd√°n√≠m
    print(url_uzemi)
    # print("Str√°nka byla √∫spƒõ≈°nƒõ naƒçtena.")
    # print("\nKontrola okresn√≠ch URL:")
    # for i, (okres, url) in enumerate(okres_urls.items(), start=1):
    #     try:
    #         response = requests.get(url, timeout=5)  # –¢–∞–π–º–∞—É—Ç 5 —Å–µ–∫—É–Ω–¥
    #         if response.status_code == 200:
    #             print(f"{i}. ‚úÖ {okres}: OK ({url})")
    #         else:
    #             print(f"{i}. ‚ùå {okres}: CHYBA {response.status_code} ({url})")
    #     except requests.exceptions.RequestException as e:
    #         print(f"{i}. ‚ö†Ô∏è {okres}: S√≠≈•ov√° chyba ({url}) ({e})")